{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T20:58:43.264071Z",
     "start_time": "2024-10-01T20:58:41.156235Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": "import jax\nimport jax.numpy as jnp\n\nfrom reinforce.neural.network import (\n    StochasticMuZeroNetwork,\n    create_network,\n    representation_forward,\n    prediction_forward,\n    afterstate_dynamics_forward,\n    afterstate_prediction_forward,\n    dynamics_forward,\n    encoder_forward,\n    count_parameters,\n)\n\nfrom twentyfortyeight.envs import TwentyFortyEight"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef26a10e28dca5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T20:58:43.853018Z",
     "start_time": "2024-10-01T20:58:43.265054Z"
    }
   },
   "outputs": [],
   "source": "# ##>: Create the Stochastic MuZero network with all 6 components.\n# ##>: observation_shape=(16,) for 4x4 board flattened.\nkey = jax.random.PRNGKey(42)\nnetwork = create_network(\n    key=key,\n    observation_shape=(16,),\n    hidden_size=256,\n    num_blocks=10,\n    num_actions=4,\n    codebook_size=32,\n)\n\nprint(f'Network config: {network.config}')\nprint(f'Total parameters: {count_parameters(network):,}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c56f5c9d815b7f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T20:58:43.855296Z",
     "start_time": "2024-10-01T20:58:43.853679Z"
    }
   },
   "outputs": [],
   "source": "# ##>: Initialize game environment (not encoded - we use raw 4x4 board).\ngame = TwentyFortyEight(encoded=False)\n_ = game.reset()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7af73f3738aad1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T20:58:43.859133Z",
     "start_time": "2024-10-01T20:58:43.856575Z"
    }
   },
   "outputs": [],
   "source": "# ##>: Get observation and convert to JAX array with batch dimension.\nobs = jnp.array(game.observation.flatten())[None, :]  # Shape: (1, 16)\nprint(f'Observation shape: {obs.shape}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ca5ce7331328d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T20:58:44.268916Z",
     "start_time": "2024-10-01T20:58:43.859880Z"
    }
   },
   "outputs": [],
   "source": "# ##>: Test representation (h): observation -> hidden state.\nhidden_state = representation_forward(network, obs)\nprint(f'Hidden state shape: {hidden_state.shape}')\nprint(f'Hidden state sample: {hidden_state[0, :5]}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28420409afcaf99f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T20:59:25.879579Z",
     "start_time": "2024-10-01T20:59:25.876932Z"
    }
   },
   "outputs": [],
   "source": "# ##>: Test prediction (f): hidden state -> (policy_logits, value).\npolicy_logits, value = prediction_forward(network, hidden_state)\nprint(f'Policy logits shape: {policy_logits.shape}')\nprint(f'Policy logits: {policy_logits}')\nprint(f'Policy probs: {jax.nn.softmax(policy_logits)}')\nprint(f'Value: {value}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5650e18515be14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T20:58:44.519758Z",
     "start_time": "2024-10-01T20:58:44.273783Z"
    }
   },
   "outputs": [],
   "source": "# ##>: Test afterstate dynamics (φ): (state, action) -> afterstate.\naction = jax.nn.one_hot(0, 4)[None, :]  # Action 0 (left), one-hot encoded\nafterstate = afterstate_dynamics_forward(network, hidden_state, action)\nprint(f'Afterstate shape: {afterstate.shape}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c485e75606a326b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T20:59:21.663559Z",
     "start_time": "2024-10-01T20:59:21.659066Z"
    }
   },
   "outputs": [],
   "source": "# ##>: Test afterstate prediction (ψ): afterstate -> (Q-value, chance_logits).\nq_value, chance_logits = afterstate_prediction_forward(network, afterstate)\nprint(f'Q-value: {q_value}')\nprint(f'Chance logits shape: {chance_logits.shape}')\nprint(f'Chance probs (top 5): {jax.nn.softmax(chance_logits)[0, :5]}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5014f5fcdf05f8d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T20:59:29.176230Z",
     "start_time": "2024-10-01T20:59:29.173096Z"
    }
   },
   "outputs": [],
   "source": "# ##>: Test dynamics (g): (afterstate, chance_code) -> (next_state, reward).\nchance_code = jax.nn.one_hot(0, 32)[None, :]  # Chance code 0, one-hot encoded\nnext_state, reward = dynamics_forward(network, afterstate, chance_code)\nprint(f'Next state shape: {next_state.shape}')\nprint(f'Reward: {reward}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51aa45c934cd2d67",
   "metadata": {},
   "outputs": [],
   "source": "# ##>: Test encoder (e): observation -> chance_code.\n# ##>: This encodes the observation to a discrete chance code using straight-through estimation.\nencoded_chance = encoder_forward(network, obs)\nprint(f'Encoded chance shape: {encoded_chance.shape}')\nprint(f'Encoded chance (should be one-hot-ish): {encoded_chance[0, :10]}')\nprint(f'Argmax of encoded chance: {jnp.argmax(encoded_chance, axis=-1)}')"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}